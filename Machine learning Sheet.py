# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WRdroN9oNC9YaJch-dNw6hu66z3gn5OC
"""

# ğŸ“Œ MACHINE LEARNING CHEAT SHEET - DATA ANALYST RNCP NIVEAU 7 ğŸ“Š

---

# ğŸ§  **INTRODUCTION AU MACHINE LEARNING**

Le **Machine Learning** (ML) permet aux ordinateurs d'apprendre Ã  partir de donnÃ©es sans Ãªtre explicitement programmÃ©s. Il est utilisÃ© pour **prÃ©dire**, **classer** et **dÃ©tecter des tendances**.

Types d'apprentissage :
- **SupervisÃ©** : Apprentissage basÃ© sur des donnÃ©es Ã©tiquetÃ©es (ex : classification d'images, rÃ©gression des prix immobiliers).
- **Non supervisÃ©** : Apprentissage basÃ© sur des donnÃ©es non Ã©tiquetÃ©es (ex : segmentation de clients).
- **Apprentissage par renforcement** : Un agent apprend Ã  interagir avec un environnement pour maximiser une rÃ©compense (ex : IA jouant aux Ã©checs).

---

# ğŸ“¥ **IMPORTATION DES LIBRAIRIES ESSENTIELLES**


import numpy as np  # Manipulation des tableaux de donnÃ©es
import pandas as pd  # Manipulation et analyse des donnÃ©es
import matplotlib.pyplot as plt  # Visualisation basique
import seaborn as sns  # Visualisation avancÃ©e
from sklearn.model_selection import train_test_split  # SÃ©paration des donnÃ©es
from sklearn.preprocessing import StandardScaler  # Normalisation des donnÃ©es
from sklearn.linear_model import LinearRegression  # ModÃ¨le de rÃ©gression linÃ©aire
from sklearn.metrics import mean_squared_error, accuracy_score  # Ã‰valuation des modÃ¨les
```

---

# ğŸ“Š **1. CHARGER ET PRÃ‰PARER LES DONNÃ‰ES**

Avant d'entraÃ®ner un modÃ¨le, il faut charger et nettoyer les donnÃ©es.

```
# Charger un dataset exemple
df = pd.read_csv('data.csv')  # Charger un fichier CSV

# Afficher les premiÃ¨res lignes
df.head()

# VÃ©rifier les valeurs manquantes
df.isnull().sum()

# Remplacer les valeurs manquantes par la moyenne
df.fillna(df.mean(), inplace=True)
```

---

# âœ‚ï¸ **2. SÃ‰PARER LES DONNÃ‰ES EN TRAIN ET TEST**

```
X = df.drop(columns=['target'])  # Features (variables indÃ©pendantes)
y = df['target']  # Target (variable Ã  prÃ©dire)

# SÃ©parer en donnÃ©es d'entraÃ®nement (80%) et de test (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

---

# âš–ï¸ **3. NORMALISER LES DONNÃ‰ES**

Certains modÃ¨les fonctionnent mieux avec des donnÃ©es normalisÃ©es.

```python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
```

---

# ğŸ”® **4. ENTRAÃNER UN MODÃˆLE DE MACHINE LEARNING**

## ğŸ”¹ **RÃ‰GRESSION LINÃ‰AIRE (PrÃ©diction d'une valeur continue)**
```python
model = LinearRegression()  # Initialisation du modÃ¨le
model.fit(X_train, y_train)  # EntraÃ®nement du modÃ¨le

# PrÃ©diction sur les donnÃ©es de test
y_pred = model.predict(X_test)

# Ã‰valuation du modÃ¨le
mse = mean_squared_error(y_test, y_pred)  # Erreur quadratique moyenne
print(f'Erreur quadratique moyenne : {mse}')
```

---

## ğŸ”¹ **CLASSIFICATION (PrÃ©diction d'une catÃ©gorie)**

Exemple avec une **rÃ©gression logistique**.

```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Ã‰valuation du modÃ¨le
accuracy = accuracy_score(y_test, y_pred)  # PrÃ©cision du modÃ¨le
print(f'PrÃ©cision : {accuracy}')
```

---

# ğŸ¯ **5. INTERPRÃ‰TATION DES RÃ‰SULTATS**

- **RÃ©gression linÃ©aire** â†’ Une faible erreur indique une bonne prÃ©diction.
- **Classification** â†’ Une haute prÃ©cision indique un bon modÃ¨le.
- **Visualisation** :

```python
plt.scatter(y_test, y_pred)
plt.xlabel('Valeurs rÃ©elles')
plt.ylabel('PrÃ©dictions')
plt.title('Comparaison des valeurs rÃ©elles vs prÃ©dictions')
plt.show()
```

---

# ğŸ›  **6. AMÃ‰LIORATION DU MODÃˆLE**

- **Ajouter plus de donnÃ©es**
- **Essayer d'autres modÃ¨les (arbres de dÃ©cision, forÃªts alÃ©atoires, SVM, rÃ©seaux de neurones)**
- **Effectuer un rÃ©glage d'hyperparamÃ¨tres (GridSearchCV, RandomizedSearchCV)**

ğŸ’¡ **Astuce** : Toujours tester plusieurs modÃ¨les et comparer leurs performances.

ğŸš€ **Maintenant, tu peux appliquer ces concepts sur des datasets rÃ©els !**