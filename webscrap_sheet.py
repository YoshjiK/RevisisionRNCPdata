# -*- coding: utf-8 -*-
"""WEBSCRAP Sheet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IxmzzE5Q2WAsBBCxOR_io1Hgx_r9ztHv
"""

# üìå Comprendre le Web Scraping en Python

# üï∏Ô∏è C'est quoi le Web Scraping ?
# Le Web Scraping est une technique permettant d'extraire automatiquement des donn√©es d'un site web.
# Il est utilis√© pour collecter des informations en masse, analyser des tendances et cr√©er des bases de donn√©es exploitables.

# üìä Les biblioth√®ques principales pour le Web Scraping
import requests  # Permet de r√©cup√©rer le code HTML d'une page web
from bs4 import BeautifulSoup  # Analyse et extrait des donn√©es HTML
from selenium import webdriver  # Automatisation des interactions avec un site web
from selenium.webdriver.common.by import By  # Permet de s√©lectionner des √©l√©ments sur une page

# ‚öôÔ∏è 1. R√©cup√©rer une page web avec Requests
# Requests est utilis√© pour envoyer une requ√™te √† un site web et r√©cup√©rer son code source HTML.
# C'est la base du Web Scraping car il permet d'obtenir la structure du site.
url = 'https://example.com'  # L'URL de la page que l'on veut scraper
response = requests.get(url)  # Envoi d'une requ√™te HTTP GET au site web
print(response.text)  # Affiche le code HTML de la page r√©cup√©r√©e

# ü•£ 2. Extraire des √©l√©ments pr√©cis avec BeautifulSoup
# BeautifulSoup permet d'analyser et de manipuler le code HTML obtenu.
# On va parser le HTML pour extraire des informations sp√©cifiques comme le titre ou un paragraphe.
html = '<html><body><h1>Bienvenue</h1><p class="desc">Ceci est un texte.</p></body></html>'
soup = BeautifulSoup(html, 'html.parser')  # Cr√©ation de l'objet BeautifulSoup qui va analyser le HTML

# Extraire le titre de la page (√©l√©ment <h1>)
titre = soup.h1.text  # Acc√®de au premier √©l√©ment <h1> et r√©cup√®re son texte
print(titre)  # Affiche 'Bienvenue'

# Extraire un paragraphe sp√©cifique
paragraphe = soup.find('p', class_='desc').text  # Trouve un √©l√©ment <p> avec la classe 'desc' et r√©cup√®re son texte
print(paragraphe)  # Affiche 'Ceci est un texte.'

# üöÄ 3. G√©rer les sites dynamiques avec Selenium
# Certains sites utilisent du JavaScript pour charger du contenu apr√®s le chargement initial de la page.
# Selenium permet d'automatiser un navigateur pour r√©cup√©rer ces donn√©es.

browser = webdriver.Chrome()  # Ouvre un navigateur Chrome
browser.get('https://example.com')  # Charge la page web

# Attendre que la page charge compl√®tement et extraire un titre apr√®s le rendu du JavaScript
titre_selenium = browser.find_element(By.TAG_NAME, 'h1').text  # S√©lectionne l'√©l√©ment <h1> et r√©cup√®re son texte
print(titre_selenium)  # Affiche le titre r√©cup√©r√© apr√®s le rendu JavaScript

browser.quit()  # Fermer le navigateur une fois le scraping termin√©

# ‚ö†Ô∏è 4. Respecter les r√®gles du Web Scraping
# - Toujours v√©rifier les conditions d'utilisation du site (certains interdisent le scraping)
# - Ne pas scraper trop souvent pour √©viter de surcharger un site
# - Ne pas collecter d'informations sensibles (donn√©es personnelles, mots de passe, etc.)
# - V√©rifier le fichier robots.txt d'un site pour conna√Ætre les restrictions (certains bloquent l'acc√®s aux robots)

# üìå R√©capitulatif des √©tapes du Web Scraping
# 1Ô∏è‚É£ Comprendre la structure HTML d'un site et identifier les donn√©es utiles
# 2Ô∏è‚É£ R√©cup√©rer la page web avec requests pour obtenir son code HTML
# 3Ô∏è‚É£ Extraire les donn√©es avec BeautifulSoup en s√©lectionnant les bons √©l√©ments
# 4Ô∏è‚É£ G√©rer les pages dynamiques avec Selenium lorsque le contenu est g√©n√©r√© en JavaScript
# 5Ô∏è‚É£ Respecter les r√®gles √©thiques et l√©gales du Web Scraping

# En ma√Ætrisant ces bases, tu peux collecter et analyser des tonnes de donn√©es facilement ! üöÄ